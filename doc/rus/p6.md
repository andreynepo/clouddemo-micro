### [Содержание](../../README.md)

### [Назад: 5. Запуск приложения](p5.md)
### [Далее: 7. Завершение и очистка](p7.md)
# 6. Работа с кластером Kubernetes

## 6.1. Пример быстрого обновления контейнера

Сейчас для генерации облака слов используется стандартная сине-зеленая цветовая схема.

Изменим цветовую схему для иллюстрации концепции быстрого развертывания изменений в микросервисах.

Пометьте имеющийся Docker образ **wc** номером версии с цветом:

##### [039]

```bash
$ docker tag $REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc:latest $REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc:1.0-green
```

Отредактируйте файл, который генерирует облако слов.

##### [040]

```bash
$ nano $HOME/workshop/clouddemo-micro/clouddemo-wc/docker/context/app/wc.py
```

Пролистайте вниз до строки **def genwordcloud (fulltext):**

Раскомментируйте строку:

```
#        wordcloud.recolor (color_func=color_func, random_state=3)
```

Эта команда вызывает функцию, изменяющую цвет облака слов.

Сохраните файл при выходе (в nano используйте сочетание **Ctrl+X**, затем нажмите **Y** и **Enter**).

Выполните следующие команды:

##### [041]

```bash
$ docker build -t $REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc:1.0-red clouddemo-wc/docker/
```

```
Sending build context to Docker daemon   5.12kB
Step 1/10 : FROM python:3.7-slim
...
Successfully built 90083ee72432
Successfully tagged eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc:1.0-red
```

Можно посмотреть список образов:

##### [042]

```bash
$ docker images
```

```
REPOSITORY                                                  TAG                 IMAGE ID            CREATED             SIZE
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc      1.0-red             7412658ae053        13 seconds ago      307MB
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc      1.0-green           2b31b55ce779        12 minutes ago      307MB
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc      latest              2b31b55ce779        12 minutes ago      307MB
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/db      latest              fed92ce41a83        12 minutes ago      330MB
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/api     latest              a23bbeeda841        13 minutes ago      353MB
eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/front   latest              7fc8a7544bcc        15 minutes ago      95MB
python                                                      3.7-slim            74ac77e9873a        2 days ago          179MB
debian                                                      buster-slim         8e022c70c28b        3 days ago          69.2MB
```

Выполните следующие команды:

##### [043]

```bash
$ docker push $REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc
```

```
The push refers to repository [eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro-wc]
9130414ff7f5: Pushed
...
```

```bash
$ kubectl set image deployment/wc wc=$REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc:1.0-red --record
```

```
deployment.extensions/wc image updated
```

Через некоторое время обновленный контейнер загрузится и новая версия pod будет запушена поэтапно.

##### [044]

```bash
$ kubectl get pods
```

```
NAME                     READY   STATUS        RESTARTS   AGE
api-7679c7fb4b-c5z2s     1/1     Running       1          13h
api-7679c7fb4b-kz25v     1/1     Running       0          14h
api-7679c7fb4b-nzdgz     1/1     Running       0          13h
api-7679c7fb4b-tgrtf     0/1     Pending       0          13h
db-579b47b499-88q6h      1/1     Running       0          13h
db-579b47b499-8drqx      1/1     Running       0          13h
front-7545444c66-6q59l   1/1     Running       0          13h
front-7545444c66-ttv2r   1/1     Running       0          13h
wc-59577c8b5f-pwtgw      1/1     Terminating   0          13h
wc-59577c8b5f-wpxbn      1/1     Terminating   0          13h
wc-8449dc49b5-cksfr      1/1     Running       0          16s
wc-8449dc49b5-t2m6n      1/1     Running       0          24s
```

После загрузки и обработки новой картинки в приложении облако слов будет перестроено в новой цветовой гамме (облако слов генерируется один раз при загрузке каждой новой картинки).

![](media/p6/image1.png)

## 6.2. История развертывания и откат к предыдущей версии

Можно вновь изменить образ, выполнив команду:

##### [045]

```bash
$ kubectl set image deployment/wc wc=$REGION.ocir.io/$NAMESPACE/clouddemo-micro/wc:1.0-green --record
```

```
deployment.extensions/wc image updated
```

Теперь можно посмотреть историю развертывания образов. Выполните команду:

##### [046]

```bash
$ kubectl rollout history deployment wc
```

```
deployment.extensions/wc 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/wc wc=eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc:1.0-red --record=true
3         kubectl set image deployment/wc wc=eu-frankfurt-1.ocir.io/frxhexdipnsp/clouddemo-micro/wc:1.0-green --record=true
```

В результате выполнения команды показаны 3 ревизии в истории развертывания: первоначальная (1), которая имела метку `latest`, (2) `1.0-red` и (3) `1.0-green`.

Можно вернуться к предыдущей версии образа, выполнив команду:

##### [047]

```bash
$ kubectl rollout undo deployment wc
```

```
deployment.extensions/wc
```

В результате будет создана новая ревизия развертывания, в которой будет отменено последнее изменение.

Можно вернуться к любой ревизии в сохраненной истории:

##### [048]

```bash
$ kubectl rollout history deployment wc
```

```bash
$ kubectl rollout undo deployment wc --to-revision=1
```

## 6.3. Изменение секретов

Проверим работу с учетными данными в Kubernetes.

Поменяем пароль пользователя базы данных **demo**.

##### [049]

```bash
$ sqlplus admin@clouddemo_tp
```

Введите пароль пользователя базы данных **admin**.

Замените пароль пользователя **demo** на новый:

##### [050]

```sql
SQL> ALTER USER DEMO IDENTIFIED BY "myWSPassword_02";
```

```
User altered.
```


Приложение пока еще продолжает работать с базой данных, поскольку сессии подключения к базе данных не закрыты.

Можно закрыть сессии из **sqlplus** или удалив pod с доступом к базе данных.

Способ через **sqlplus**:

##### [051]

```sql
SQL> SELECT SID, SERIAL#, STATUS FROM V$SESSION WHERE USERNAME = 'DEMO';

       SID    SERIAL# STATUS
---------- ---------- --------
      3934      22834 INACTIVE
     22250      58494 INACTIVE

SQL> ALTER SYSTEM KILL SESSION '3934, 22834';

System altered.

SQL> ALTER SYSTEM KILL SESSION '22250, 58494';

System altered.
```

Ваши значения `SID` и `SERIAL#` будут другие. Подставьте в команды ваши значения.

Проверьте в приложении, что доступ к базе данных больше не работает.



Альтернативно можно удалить pod, относящиеся к базе данных. Если вы уже закрыли сессии через sqlplus, то можете пропустить этот шаг и перейти к удалению **secret**.

##### [052]

```sql
SQL> quit
```

```bash
$ kubectl get pods
```

```
NAME                     READY   STATUS    RESTARTS   AGE
api-5ffc6789f8-92qdx     1/1     Running   0          16m
api-5ffc6789f8-mst6c     1/1     Running   0          16m
api-5ffc6789f8-wd8fs     1/1     Running   0          16m
api-5ffc6789f8-zfxcq     0/1     Pending   0          16m
db-5c87d77889-gcpk5      1/1     Running   0          16m
db-5c87d77889-rfxrc      1/1     Running   0          16m
front-6489674dcf-79wsv   1/1     Running   0          16m
front-6489674dcf-vhnjx   1/1     Running   0          16m
wc-9bcfc4d98-5tfxk       1/1     Running   0          16m
wc-9bcfc4d98-m75rs       1/1     Running   0          16m
```

Удалите pod базы данных:

##### [053]

```bash
$ kubectl delete pod <pod_db_1> <pod_db_2>
```

Вставьте через пробел имена всех ваших pod, относящихся к базе данных: `db-...`

Новые pod будут созданы автоматически, но уже не смогут работать с базой данных. 

Проверьте это в приложении.

Удалите **secret** следующей командой:

##### [054]

```bash
$ kubectl delete secret db-secret
```

Создайте **secret** с новым паролем:

##### [055]

```bash
$ kubectl create secret generic db-secret --from-literal=username=demo --from-literal=password=myWSPassword_02 --from-literal=connection=clouddemo_tp
```

Теперь удалите pod с базой данных, чтобы создались новые pod, которые получат новые параметры **secret**.

##### [056]

```bash
$ kubectl get pods
```

```
NAME                     READY   STATUS    RESTARTS   AGE
api-5ffc6789f8-92qdx     1/1     Running   0          22m
api-5ffc6789f8-mst6c     1/1     Running   0          22m
api-5ffc6789f8-wd8fs     1/1     Running   0          22m
api-5ffc6789f8-zfxcq     0/1     Pending   0          22m
db-5c87d77889-5gpk8      1/1     Running   0          91s
db-5c87d77889-zfccm      1/1     Running   0          91s
front-6489674dcf-79wsv   1/1     Running   0          22m
front-6489674dcf-vhnjx   1/1     Running   0          22m
wc-9bcfc4d98-5tfxk       1/1     Running   0          22m
wc-9bcfc4d98-m75rs       1/1     Running   0          22m
```

```bash
$ kubectl delete pod <pod_db_1> <pod_db_2>
```

Вставьте через пробел имена всех ваших pod, относящихся к базе данных: `db-...`

Новые pod будут созданы автоматически, и будут использовать новые параметры **secret**, поэтому  снова смогут работать с базой данных. 

Проверьте это в приложении.

## 6.4. Масштабирование кластера

Масштабирование pod выполняется следующим образом:

##### [057]

```bash
$ kubectl scale --replicas=5 deployment api
```

```bash
$ kubectl scale --replicas=1 deployment db
```

```bash
$ kubectl scale --replicas=1 deployment front
```

```bash
$ kubectl scale --replicas=1 deployment wc
```
Замените значение после `--replicas=` на требуемое количество pod.

##### [058]

```bash
$ kubectl get pods -o wide
```

```
NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE        NOMINATED NODE   READINESS GATES
api-5ffc6789f8-5bhkc     1/1     Running   0          7m20s   10.244.2.5   10.0.10.2   <none>           <none>
api-5ffc6789f8-5c7cg     0/1     Pending   0          81s     <none>       <none>      <none>           <none>
api-5ffc6789f8-8dsmw     1/1     Running   0          7m20s   10.244.0.4   10.0.10.4   <none>           <none>
api-5ffc6789f8-b2t5k     1/1     Running   0          7m20s   10.244.1.6   10.0.10.3   <none>           <none>
api-5ffc6789f8-ttx45     0/1     Pending   0          7m20s   <none>       <none>      <none>           <none>
db-575b76985c-rzx6w      1/1     Running   0          7m20s   10.244.1.5   10.0.10.3   <none>           <none>
front-6489674dcf-bzxnw   1/1     Running   0          7m20s   10.244.1.4   10.0.10.3   <none>           <none>
wc-6ff7c6c794-dwdgc      1/1     Running   0          2m53s   10.244.2.6   10.0.10.2   <none>           <none>
```

Масштабирование узлов кластера производится следующим образом:

![](media/p6/image2.png)На странице информации о кластере пролистайте ниже до раздела **Node Pools** и нажмите **Actions / Scale**.

В открывшемся окне укажите требуемое количество рабочих узлов (например, 4), пролистайте вниз и нажмите **Scale**.

Будут созданы (или удалены) узлы, чтобы общее их количество равнялось требуемому.

Если установить размер **Node Pool** в 0, то рабочие узлы этого пула будут удалены, нагрузка с них убрана (а в отсутствии других пулов все pod будут поставлены в режим Pending), однако кластер удален не будет.

Также можно масштабировать кластер командой oci cli:

##### [059]

```bash
$ oci ce node-pool update --size 2 --node-pool-id <Paste your Node Pool OCID Here> 
```

Вставьте OCID вашего **Node Pool**. Замените значение после `--size` на нужный размер пула.
### [Назад: 5. Запуск приложения](p5.md)
### [Далее: 7. Завершение и очистка](p7.md)